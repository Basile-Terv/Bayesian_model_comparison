{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lea/anaconda3/envs/opt_transport/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#from data import regression_datasets, get_regression_data\n",
    "import gpytorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import argparse\n",
    "\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "from botorch.models import SingleTaskVariationalGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--m M] [--losstype LOSSTYPE]\n",
      "                             [--dataset DATASET] [--ntrain NTRAIN]\n",
      "                             [--ntrial NTRIAL]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/Lea/Library/Jupyter/runtime/kernel-v2-61230PvNASFgsIsEP.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lea/anaconda3/envs/opt_transport/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def get_mll(gp, x, y):\n",
    "    N = len(x)\n",
    "    x = gp.feature_extractor(x)\n",
    "    x = gp.scale_to_bounds(x)\n",
    "    covar_matrix = gp.covar_module(x,x).evaluate()\n",
    "    covar_matrix += gp.likelihood.noise * torch.eye(N).to(x.device)\n",
    "    log_mll = - 0.5 * (y.T @ torch.inverse(covar_matrix)) @ y \n",
    "    log_mll += - 0.5 * torch.logdet(covar_matrix)\n",
    "    log_mll += - 0.5 * N * np.log(2 * np.pi)\n",
    "\n",
    "    return log_mll\n",
    "\n",
    "def CondtionalMLL(gp, x, y, xm, ym):\n",
    "    return get_mll(gp, x, y) - get_mll(gp, xm, ym)\n",
    "\n",
    "def RMSE(preds, targets):\n",
    "    return (preds.squeeze().cpu() - targets.squeeze().cpu()).pow(2).mean().pow(0.5)\n",
    "\n",
    "\n",
    "class LargeFeatureExtractor(torch.nn.Sequential):\n",
    "    def __init__(self, data_dim):\n",
    "        super(LargeFeatureExtractor, self).__init__()\n",
    "        self.add_module('linear3', torch.nn.Linear(data_dim, 50))\n",
    "        self.add_module('relu3', torch.nn.ReLU())\n",
    "        self.add_module('linear4', torch.nn.Linear(50, 2))\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "        def __init__(self, train_x, train_y, likelihood, feature_extractor):\n",
    "            super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            self.covar_module = gpytorch.kernels.GridInterpolationKernel(\n",
    "                gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=2)),\n",
    "                num_dims=2, grid_size=100\n",
    "            )\n",
    "            self.feature_extractor = feature_extractor\n",
    "\n",
    "            # This module will scale the NN features so that they're nice values\n",
    "            self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # We're first putting our data through a deep net (feature extractor)\n",
    "            projected_x = self.feature_extractor(x)\n",
    "            projected_x = self.scale_to_bounds(projected_x)  # Make the NN values \"nice\"\n",
    "\n",
    "            mean_x = self.mean_module(projected_x)\n",
    "            covar_x = self.covar_module(projected_x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(m, losstype,dataset,ntrain=200,ntrial=10):\n",
    "    \n",
    "    data = get_regression_data(dataset)\n",
    "    train_x = torch.FloatTensor(data.X_train)[:ntrain]\n",
    "    train_y = torch.FloatTensor(data.Y_train).squeeze()[:ntrain]\n",
    "    test_x = torch.FloatTensor(data.X_test)\n",
    "    test_y = torch.FloatTensor(data.Y_test).squeeze()\n",
    "    data_dim = train_x.size(-1)\n",
    "    m = int(m * train_x.shape[0])\n",
    "    \n",
    "    \n",
    "    rmse = torch.zeros(ntrial)\n",
    "    for trl in range(ntrial):\n",
    "\n",
    "        feature_extractor = LargeFeatureExtractor(data_dim)\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model = GPRegressionModel(train_x, train_y, likelihood,\n",
    "                                  feature_extractor)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            use_cuda=True\n",
    "            model = model.cuda()\n",
    "            likelihood = likelihood.cuda()\n",
    "            train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()\n",
    "\n",
    "        training_iterations = 100\n",
    "\n",
    "        # Find optimal model hyperparameters\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "\n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': model.feature_extractor.parameters()},\n",
    "            {'params': model.covar_module.parameters()},\n",
    "            {'params': model.mean_module.parameters()},\n",
    "            {'params': model.likelihood.parameters()},\n",
    "        ], lr=0.01)\n",
    "\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        def train(losstype='cmll'):\n",
    "            iterator = tqdm.tqdm(range(training_iterations))\n",
    "            for i in iterator:\n",
    "                # Zero backprop gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Get output from model\n",
    "                output = model(train_x)\n",
    "                # Calc loss and backprop derivatives\n",
    "                if losstype=='mll':\n",
    "                    loss = -mll(output, train_y)\n",
    "                if losstype=='cmll':\n",
    "                    order = torch.randperm(train_x.shape[0])        \n",
    "                    xm = train_x[order[:m]]\n",
    "                    xstar = train_x[order[m:]]\n",
    "\n",
    "                    ym = train_y[order[:m]]\n",
    "                    ystar = train_y[order[m:]]\n",
    "                    loss = -CondtionalMLL(model, train_x, train_y, xm, ym)\n",
    "\n",
    "                loss.backward()\n",
    "                iterator.set_postfix(loss=loss.item())\n",
    "                optimizer.step()\n",
    "\n",
    "        train(losstype=losstype)\n",
    "        model.eval();\n",
    "        test_preds = model(test_x).mean\n",
    "        rmse[trl] = RMSE(test_preds, test_y)\n",
    "        \n",
    "    fpath = \"./saved-outputs/\"\n",
    "    fname = \"exactdkl\" + dataset + \"_ntrain\" + str(ntrain) + \"_\" + losstype\n",
    "    if losstype == \"cmll\":\n",
    "        fname += \"_\" + str(m) + \"m\"\n",
    "    fname += \".pt\"\n",
    "    \n",
    "    torch.save(rmse, fpath + fname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_transport",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
